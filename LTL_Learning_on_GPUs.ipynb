{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "authorship_tag": "ABX9TyPlexA9g2WcJQ88F63YYOd7",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/MojtabaValizadeh/ltl-learning-on-gpus/blob/main/LTL_Learning_on_GPUs.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <strong>LTL Learning on GPUs</strong>"
      ],
      "metadata": {
        "id": "CIr-_nboWU0o"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "This notebook contains the code and other artifacts for the  paper\n",
        "\n",
        "> **LTL Learning on GPUs** \\\\\n",
        "> **CAV 2024, 36th International Conference on Computer Aided Verification**\n",
        "\n",
        "by `Mojtaba Valizadeh`, `NathanaÃ«l Fijalkow` and `Martin Berger`.\n",
        "\n",
        "A draft of the paper is available at https://arxiv.org/abs/2402.12373."
      ],
      "metadata": {
        "id": "Tt8KHDWrWlKp"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <strong>Google Colab's GPUs</strong>\n",
        "\n",
        "To optimize memory and performance, we recommend upgrading your Colab to `Pro` or `Pro+` versions. These paid versions offer larger memory limits, faster processing speeds, and advanced hardware acceleration, enabling users to execute complex operations with greater efficiency. By contrast, the `free version` of Colab may be subject to limitations that can impact the performance and accuracy of the following tasks.\n",
        "\n",
        "**To upgrade to Colab Pro:**\n",
        "\n",
        "- Find the `Colab Pro` tab in `Tools > Settings`.\n",
        "- Choose your desired plan: `Colab Pro` or `Colab Pro+`.\n",
        "- Follow the prompts to enter your billing information and complete the purchase process.\n",
        "\n",
        "Colab Pro is billed on a monthly basis, and you can cancel at any time. Additionally, some countries or regions may not be eligible to purchase Colab Pro at this time, so you may need to check if it is available in your area before proceeding.\n",
        "\n",
        "**Note:** Even with the free version of Colab, you should be able to connect to certain types of GPUs, though there are some limitations. Everything you need is already set up in this notebook. Now, please run the following script to check if you are connected to a GPU. To run a cell in Colab, you can either click on the \"play\" button located on the left side of the cell, or you can press \"Shift+Enter\" on your keyboard while the cell is selected."
      ],
      "metadata": {
        "id": "Ld1EBKJUmO_Q"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check if connected to GPU\n",
        "gpu_info = ! nvidia-smi\n",
        "gpu_info = '\\n'.join(gpu_info)\n",
        "if 'failed' in gpu_info or 'not found' in gpu_info:\n",
        "  print('GPU not found!')\n",
        "  print(\"At 'Runtime > Change runtime type', please choose `GPU` for `Hardware accelerator` and try again.\")\n",
        "else:\n",
        "    ! nvidia-smi\n",
        "    print()\n",
        "    print(\"Great! You are connected to a GPU! Please go on ...\")"
      ],
      "metadata": {
        "id": "xtBuJ5_jiLBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <strong>Initialization</strong>\n",
        "\n",
        "To begin, please run the code below to transfer all of the necessary requirements, including the codes, dependencies, benchmarks, etc, to this notebook."
      ],
      "metadata": {
        "id": "v9lFOLI4Y6HN"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "if not os.path.isdir(\"/content/ltl-learning-on-gpus\"):\n",
        "    !git clone https://github.com/MojtabaValizadeh/ltl-learning-on-gpus\n",
        "    print(\"Done\")\n",
        "else:\n",
        "    print(\"The repository already exists in the notebook!\")"
      ],
      "metadata": {
        "id": "K_r5lKKzY_ff"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <strong>Compile the GPU code</strong>\n",
        "\n",
        "To compile and run the GPU code, please run the following scripts."
      ],
      "metadata": {
        "id": "b56Ty7UwZEJe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Compiling the GPU code...\")\n",
        "cu_path  = \"/content/ltl-learning-on-gpus/code/ltli6463.cu\"\n",
        "lib_path = \"/content/ltl-learning-on-gpus/code/modified_libraries\"\n",
        "\n",
        "! nvcc --extended-lambda -D MEASUREMENT_MODE -I {lib_path} {cu_path} -o ltli6463\n",
        "\n",
        "print(\"Done\")"
      ],
      "metadata": {
        "id": "-x8pn8peZGqs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "**Note** You can remove \"-D MEASUREMENT_MODE\" from the compilation instructions above to see more logs and information while running the code."
      ],
      "metadata": {
        "id": "bHdIP0bodwg9"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <strong>Run the GPU code</strong>\n",
        "\n",
        "In order to run any small examples (with fewer than 64 traces with max length of 63 in the positive and negative traces in the input file), you can use the GPU code directly by executing\n",
        "```\n",
        "! ./ltli6463 <input_path> <c1> <c2> <c3> <c4> <c5> <c6> <c7> <c8> <maxCost> <RlxUnqChkType> <negType>\n",
        "```\n",
        "where\n",
        "1. `input_path` refers to the address of the input file that contains your positive and negative traces.\n",
        "2. (`c1`, `c2`, `c3`, `c4`, `c5`, `c6`, `c7`, `c8`) are 8 small positive integers for the costs of (`a`, `~`, `&`, `|`, `X`, `F`, `G`, `U`).\n",
        "3. `maxCost` parameter is an integer that sets an upper limit on the cost of the regular expression that the algorithm will search for. In most cases, you can use a reasonably large integer, such as 500, which is appropriate for our cost functions.\n",
        "4. `RlxUnqChkType` is an integer in {`1`, `2`, `3`} for choosing one of the approximate uniqueness check algorithms `firstBitsPlusStrides`, `theFirstKPercent`, `ModifiedMuellerHash`.\n",
        "5. `negType` is an integer in {`1`, `2`} for choosing one of the strategies for using negation `negOfPhi` or `negOfChar`.\n",
        "\n",
        "For example, to run the first example from the existing benchmarks, use the code below."
      ],
      "metadata": {
        "id": "1m3TmpawZNT-"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "input_path = \"/content/ltl-learning-on-gpus/benchmarks/standard_benchmarks_1/flie_benchmarks/TracesFiles/abscence/Ab0.trace\"\n",
        "\n",
        "c1 = 1              # cost of (a) alphabet\n",
        "c2 = 1              # cost of (~) negation\n",
        "c3 = 1              # cost of (&) intersection\n",
        "c4 = 1              # cost of (|) union\n",
        "c5 = 1              # cost of (X) neXt\n",
        "c6 = 1              # cost of (F) Finally\n",
        "c7 = 1              # cost of (G) Globally\n",
        "c8 = 1              # cost of (U) Until\n",
        "maxCost = 500       # A big-enough cost\n",
        "RlxUnqChkType = 3   # 3 = ModifiedMuellerHash\n",
        "NegType = 2          # 2 = negOfChar\n",
        "\n",
        "# Run the code\n",
        "! ./ltli6463 {input_path} {c1} {c2} {c3} {c4} {c5} {c6} {c7} {c8} {maxCost} {RlxUnqChkType} {NegType}"
      ],
      "metadata": {
        "id": "l8ycD2KoZP1_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <strong>Divide-and-conquer Algorithms for bigger instances</strong>"
      ],
      "metadata": {
        "id": "198NyN7ynycf"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Let's import and install some additional dependencies. Please run the following script:"
      ],
      "metadata": {
        "id": "Buc8-lC60li1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Installing bitarray...\")\n",
        "! pip install bitarray"
      ],
      "metadata": {
        "id": "RapuVdP7h3ii"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "We are now able to call the GPU code multiple times for larger instances in some divide-and-conquer algorithms and combine the results using higher-level scripts written in Python. Apart from handling timeouts, we now have two important additional arguments:\n",
        "\n",
        "- `dcAlgo`: Specifies the divide-and-conquer algorithm to use, which can be either `DetSplit` or `RandSplit`.\n",
        "- `window`: Indicates the maximum number of traces to pass to the GPU code. In this version, `window` <= 64."
      ],
      "metadata": {
        "id": "UQLSIpi50zeb"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Please run the script below, which is another example of the existing benchmarks:"
      ],
      "metadata": {
        "id": "N_RGeKzkmGPZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import sys\n",
        "sys.path.append(\"/content/ltl-learning-on-gpus/code\")\n",
        "from dc import *\n",
        "\n",
        "# Arguments:\n",
        "input_path = \"/content/ltl-learning-on-gpus/benchmarks/standard_benchmarks_1/flie_benchmarks/TracesFiles/existence/E7.trace\"\n",
        "dcAlgo = RandSplit                  # Random splitting\n",
        "window = 64                         # 64 is max traces number in this version\n",
        "costfun = [1, 1, 1, 1, 1, 1, 1, 1]  # Costs of (a, ~, &, |, X, F, G, U)\n",
        "maxCost = 500                       # A big-enough cost\n",
        "RlxUnqChkType = 3                   # 3 = ModifiedMuellerHash\n",
        "NegType = 2                         # 2 = negOfChar\n",
        "timeout = 2000                      # 2000 sec\n",
        "\n",
        "# Run the code\n",
        "runDC(input_path, dcAlgo, window, costfun, maxCost, RlxUnqChkType, NegType, timeout)"
      ],
      "metadata": {
        "id": "eeP0y9jntNwW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# <strong>More Info</strong>\n",
        "\n",
        "If you need further information, please refer to our paper\n",
        "\n",
        "https://arxiv.org/abs/2402.12373\n",
        "\n",
        "or feel free to contact the authors directly."
      ],
      "metadata": {
        "id": "xLEQVv9AZ--f"
      }
    }
  ]
}